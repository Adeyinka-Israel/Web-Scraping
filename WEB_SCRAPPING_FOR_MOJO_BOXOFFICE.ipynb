{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec881043",
   "metadata": {},
   "source": [
    "# Box Office Mojo Web Scraping Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53abd21f",
   "metadata": {},
   "source": [
    "### Overview\n",
    "**This web scraping project focuses on extracting data from Box Office Mojo, a comprehensive database of box office statistics for movies. The goal is to gather information about various movies, including their worldwide gross income, domestic gross income, international gross income, and gross percentages.**\n",
    "\n",
    "### Target Website\n",
    "#### Website: Box Office Mojo - Yearly Worldwide Box Office\n",
    "\n",
    "**Data to Scrape\n",
    "Movie Title: Name of the movie.\n",
    "Worldwide Gross Income: Total box office earnings globally.\n",
    "Domestic Gross Income: Box office earnings within the movie's home country.\n",
    "International Gross Income: Box office earnings outside the movie's home country.\n",
    "Domestic Gross Percentage: Percentage of total gross income from the movie's home country.\n",
    "International Gross Percentage: Percentage of total gross income from international markets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa70e70",
   "metadata": {},
   "source": [
    "#### import library\n",
    "***These lines of code import the required libraries for web scraping using Python. The requests library is used to make HTTP requests to the website and retrieve the HTML content. The BeautifulSoup library is used for parsing the HTML content and extracting the desired data from it. These libraries will be essential for accessing and processing the webpage content during the web scraping process.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "583734b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2d300f",
   "metadata": {},
   "source": [
    "**This function below takes a dictionary (data) as input and writes its contents into a CSV file specified by \"fname\". It first writes the header row using the dictionary keys, and then iterates over the values to write each row of data into the CSV file. Finally, it returns a confirmation message indicating the successful creation of the CSV file.\n",
    "The function automates the process of converting data stored in a dictionary format into a CSV file. This automation saves time and effort compared to manually writing code to perform the conversion each time it's needed and can be reused.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73474b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(data, fname='default.txt'):\n",
    "    \"\"\"\n",
    "     parse a dictionary as a csv file\n",
    "    \"\"\"\n",
    "    ##csv_file = open(fname, 'w')\n",
    "    with open(fname,'w') as csv_file:\n",
    "\n",
    "        header = ','.join(data.keys())\n",
    "\n",
    "        csv_file.write(header + '\\n')\n",
    "\n",
    "    # write data on rows\n",
    "        num_rows = len(next(iter(data.values())))\n",
    "\n",
    "        for i in range(num_rows):\n",
    "            row = ','.join(str(data[key][i]) for key in data.keys())\n",
    "            csv_file.write(row + '\\n')\n",
    "\n",
    "\n",
    "    return \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cede9ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a request to the website to test if we have a succesful connection\n",
    "try:\n",
    "    \n",
    "    res = requests.get('https://www.boxofficemojo.com/year/world/?sort=rank&sortDir=asc&ref_=bo_ydw__resort#table').content\n",
    "except:\n",
    "    print(\"Unsuccesful connection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ce9f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie dictionary, this is where our data scraped will be store based on our Key and Value\n",
    "movie = {\n",
    "    'rank' : [],\n",
    "    'Movie Title':[],\n",
    "    'Worldwide':[],\n",
    "    'Domestic' : [],\n",
    "    'dom %':[],\n",
    "    'Foreign':[],\n",
    "    'For %':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5daf5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an object of BeautifulSoup\n",
    "soup = BeautifulSoup(res,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac01dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction of all table data (td) elements with the specified class from the parsed HTML content (soup)\n",
    "\n",
    "ranks = soup.find_all('td', class_='a-text-right mojo-header-column mojo-truncate mojo-field-type-rank mojo-sort-column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0961654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through the extracted rank elements and appends the text content of each element to the 'rank' key within the movie dictionary.\n",
    "for rank in ranks:\n",
    "    movie['rank'].append(rank.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "edc5921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction of all table data (td) elements with the specified class from the parsed HTML content (soup)\n",
    "\n",
    "soup.find_all('td', class_=\"a-text-left mojo-field-type-release_group\")\n",
    "Movie_title = soup.find_all('td', class_=\"a-text-left mojo-field-type-release_group\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "77332012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through the extracted Release Group elements and appends the text content of each element to the 'Movie Title' key within the movie dictionary.\n",
    "\n",
    "for title in Movie_title:\n",
    "    movie['Movie Title'].append(title.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "56ef084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction of all table data (td) elements with the specified class from the parsed HTML content (soup)\n",
    "\n",
    "soup.find_all('td', class_=\"a-text-right mojo-field-type-money\")\n",
    "World_wide = soup.find_all('td', class_=\"a-text-right mojo-field-type-money\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "cfa1e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through the extracted World wide elements and appends the text content of each element to the 'Worldwide' key within the movie dictionary.\n",
    "\n",
    "\n",
    "for world in World_wide[0::3]:\n",
    "    movie['Worldwide'].append(world.get_text().replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "b148ccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction of all table data (td) elements with the specified class from the parsed HTML content (soup)\n",
    "\n",
    "soup.find_all('td', class_=\"a-text-right mojo-field-type-money\")\n",
    "domestic = soup.find_all('td', class_=\"a-text-right mojo-field-type-money\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "cb49e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through the extracted domestic elements and appends the text content of each element to the 'Domestic' key within the movie dictionary.\n",
    "\n",
    "\n",
    "for dom in domestic[1::3]:\n",
    "    movie['Domestic'].append(dom.get_text().replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6f009170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction of all table data (td) elements with the specified class from the parsed HTML content (soup)\n",
    "\n",
    "soup.find_all('td', class_=\"a-text-right mojo-field-type-money\")\n",
    "foreign = soup.find_all('td', class_=\"a-text-right mojo-field-type-money\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1d87d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through the extracted foreign elements and appends the text content of each element to the 'Foreign' key within the movie dictionary.\n",
    "\n",
    "\n",
    "for reign in foreign[2::3]:\n",
    "    movie['Foreign'].append(reign.get_text().replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2ead745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction of all table data (td) elements with the specified class from the parsed HTML content (soup)\n",
    "\n",
    "soup.find_all('td', class_=\"a-text-right mojo-field-type-percent\")\n",
    "dom_percent = soup.find_all('td', class_=\"a-text-right mojo-field-type-percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "1ddd1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through the extracted domestic % elements and appends the text content of each element to the 'dom %' key within the movie dictionary.\n",
    "\n",
    "\n",
    "for dp in dom_percent[0::2]:\n",
    "    movie['dom %'].append(dp.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "acae4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction of all table data (td) elements with the specified class from the parsed HTML content (soup)\n",
    "\n",
    "soup.find_all('td', class_=\"a-text-right mojo-field-type-percent\")\n",
    "for_percent = soup.find_all('td', class_=\"a-text-right mojo-field-type-percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "12ad2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterating through the extracted foreign % elements and appends the text content of each element to the 'For %' key within the movie dictionary.\n",
    "\n",
    "\n",
    "for fp in for_percent[1::2]:\n",
    "    movie['For %'].append(fp.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "9481bac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Done'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_csv(movie,'movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e0a138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
